# 从函数到神经网络
整个世界都可以被抽象成为一个巨大的函数f(x)，人们可以使用f(x)来表示一个规律。
例如：y=2x+3，表示的是y的结果由x来影响。
再复杂一点：y=2x²+5x+1，这些都是用数学公式描述的规律。
但是现实中我们没办法根据一段数据生成一个完全符合的函数，于是我们采用了大致相符的函数来形容某一个现象。
现实的世界很复杂，我们通过多层非线性变换的复合可以逼近任意复杂的函数，例如，每一层都是一个简单的变换函数（如 f(Wx+b)），这就是神经网络。

# 计算神经网络的参数
当我们尝试用函数来拟合一组数据时，我们需要计算这个函数的拟合程度。
我们先计算每条数据的真实值与预测值之差，取其平方后求平均，这个平均值就称为损失函数，用于衡量模型拟合的好坏。

神经网络中，输入层、隐藏层、输出层通过多个函数进行计算；每个函数的变量都会影响最终的损失函数。我们把计算多个函数最终**输出预测值**的过程叫做**正向传播**。

我们从最终的损失函数出发，用链式法则计算损失对各层参数（以及中间激活）的梯度，这个过程叫做**反向传播**。

因此，训练通常是一个循环：
1. **正向传播**：得到预测值；
2. **计算损失**：用预测值与真实值计算损失函数；
3. **反向传播**：计算各层参数的梯度；
4. **更新参数**：据此微调权重，使模型预测越来越准。
 

